{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b935eaef",
   "metadata": {},
   "source": [
    "# Transfer Learning (EfficientNetB0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392c525-ba63-4849-9c84-ac916e4e4a2b",
   "metadata": {},
   "source": [
    "Instead of extracting high-level features, one can use pretrained models directly for classfication by adding some output layers. It is also possible to fine-tune such a model, though it is very ressource consuming.\n",
    "\n",
    "I use here the original images, as data augmentation is done by two added input layers for random horizontal flipping and random rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de4ae9-a397-46fd-9fed-96ad0dade98a",
   "metadata": {},
   "source": [
    "## 1. Models used for high-level feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85196d20-1ba9-48e7-952a-803a4dcb499a",
   "metadata": {},
   "source": [
    " **Model**         | **Size (MB)** | **Top-1 Accuracy** | **Top-5 Accuracy** | **Parameters** | **Depth** | **Time (ms) per inference step (CPU)** | **Time (ms) per inference step (GPU)** \n",
    "------------------:|--------------:|-------------------:|-------------------:|---------------:|----------:|---------------------------------------:|---------------------------------------:\n",
    " InceptionV3       | 92            | 0.779              | 0.937              | 23,851,784     | 159       | 42.25                                  | 6.86                                   \n",
    " *EfficientNetB0*    | 29            | -                  | -                  | 5,330,571      | -         | 46                                     | 4.91                                   \n",
    " ResNet50          | 98            | 0.749              | 0.921              | 25,636,712     | -         | 58.2                                   | 4.55                                   \n",
    " VGG16             | 528           | 0.713              | 0.901              | 138,357,544    | 23        | 69.5                                   | 4.16                                   \n",
    " DenseNet121       | 33            | 0.75               | 0.923              | 8,062,504      | 121       | 77.14                                  | 5.38                                   \n",
    " Xception          | 88            | 0.79               | 0.945              | 22,910,480     | 126       | 109.42                                 | 8.06                                   \n",
    " InceptionResNetV2 | 215           | 0.803              | 0.953              | 55,873,736     | 572       | 130.19                                 | 10.02                                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b81d7-6cef-4511-9297-b8b44e69366e",
   "metadata": {},
   "source": [
    "> Data source: https://keras.io/api/applications/#available-models  \n",
    "> Table converter: https://tableconvert.com/excel-to-markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac2ec4-5d94-4621-b009-32c41eac6e17",
   "metadata": {},
   "source": [
    "## 2. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f9d2a5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd44263-5da7-4531-9801-1c50270f87c9",
   "metadata": {},
   "source": [
    "## 3. Structure of `data/split` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2fcf8-6abb-47c6-bce6-d5a7940c76ca",
   "metadata": {},
   "source": [
    "```\n",
    "data/split\n",
    "└── 40X\n",
    "    ├── test\n",
    "    │   ├── adenosis\n",
    "    │   ├── ductal_carcinoma\n",
    "    │   ├── fibroadenoma\n",
    "    │   ├── lobular_carcinoma\n",
    "    │   ├── mucinous_carcinoma\n",
    "    │   ├── papillary_carcinoma\n",
    "    │   ├── phyllodes_tumor\n",
    "    │   └── tubular_adenoma\n",
    "    ├── train\n",
    "    │   ├── adenosis\n",
    "    │   ├── ductal_carcinoma\n",
    "    │   ├── fibroadenoma\n",
    "    │   ├── lobular_carcinoma\n",
    "    │   ├── mucinous_carcinoma\n",
    "    │   ├── papillary_carcinoma\n",
    "    │   ├── phyllodes_tumor\n",
    "    │   └── tubular_adenoma\n",
    "    └── val\n",
    "        ├── adenosis\n",
    "        ├── ductal_carcinoma\n",
    "        ├── fibroadenoma\n",
    "        ├── lobular_carcinoma\n",
    "        ├── mucinous_carcinoma\n",
    "        ├── papillary_carcinoma\n",
    "        ├── phyllodes_tumor\n",
    "        └── tubular_adenoma\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a9a5d",
   "metadata": {},
   "source": [
    "## 4. Define image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60745953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_generator_train = ImageDataGenerator(\n",
    "    #rescale=1/127.5,\n",
    "    #rescale=127.5,\n",
    "    #width_shift_range= 10.0,\n",
    "    #height_shift_range= 10.0,\n",
    "    #rotation_range = 20,\n",
    "    #horizontal_flip = True,\n",
    "    #vertical_flip = False,\n",
    "    #zoom_range = 0.1,\n",
    "    #channel_shift_range = 0.2,\n",
    "    #brightness_range = (0,1),\n",
    "    #shear_range = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d115c5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_generator_valtest = ImageDataGenerator(\n",
    "    #rescale=1/127.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec488d98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "image40Xtrain = image_generator_train.flow_from_directory(\n",
    "    os.path.join('data','split','40X','train'),\n",
    "    batch_size=4, \n",
    "    target_size=(460, 700),\n",
    "    class_mode = 'sparse',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78c50481",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 195 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "image40Xval = image_generator_valtest.flow_from_directory(\n",
    "    os.path.join('data','split','40X','val'),\n",
    "    batch_size=4, \n",
    "    target_size=(460, 700),\n",
    "    class_mode = 'sparse',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5114e53d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "image40Xtest = image_generator_valtest.flow_from_directory(\n",
    "    os.path.join('data','split','40X','test'),\n",
    "    batch_size=4, \n",
    "    target_size=(460, 700),\n",
    "    class_mode = 'sparse',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b92755",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a43b400",
   "metadata": {},
   "source": [
    "#### Print shape of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ff6b1b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: (4, 460, 700, 3)\n",
      "Labels: (4,)\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = image40Xtrain.next()\n",
    "print('Images:', imgs.shape)\n",
    "print('Labels:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05fa0e-5e9d-436e-b05d-729be9e3e3a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Print range of pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75018546-18fb-42ac-b8d2-ea328d580ec2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest pixel value: 24.0 \n",
      "highest pixel value: 255.0\n"
     ]
    }
   ],
   "source": [
    "print('lowest pixel value:',np.min(imgs), '\\nhighest pixel value:', np.max(imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82659bcf",
   "metadata": {},
   "source": [
    "## 5. Number of images per class for magnitude 40x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b06b53e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " train\n",
      "n: 91 , ratio: 6 : 40x adenosis\n",
      "n: 691 , ratio: 43 : 40x ductal_carcinoma\n",
      "n: 202 , ratio: 13 : 40x fibroadenoma\n",
      "n: 124 , ratio: 8 : 40x lobular_carcinoma\n",
      "n: 164 , ratio: 10 : 40x mucinous_carcinoma\n",
      "n: 116 , ratio: 7 : 40x papillary_carcinoma\n",
      "n: 87 , ratio: 5 : 40x phyllodes_tumor\n",
      "n: 119 , ratio: 7 : 40x tubular_adenoma\n",
      "1594 : Total images with magnitude 40x\n",
      "\n",
      " val\n",
      "n: 11 , ratio: 6 : 40x adenosis\n",
      "n: 86 , ratio: 44 : 40x ductal_carcinoma\n",
      "n: 25 , ratio: 13 : 40x fibroadenoma\n",
      "n: 15 , ratio: 8 : 40x lobular_carcinoma\n",
      "n: 20 , ratio: 10 : 40x mucinous_carcinoma\n",
      "n: 14 , ratio: 7 : 40x papillary_carcinoma\n",
      "n: 10 , ratio: 5 : 40x phyllodes_tumor\n",
      "n: 14 , ratio: 7 : 40x tubular_adenoma\n",
      "195 : Total images with magnitude 40x\n",
      "\n",
      " test\n",
      "n: 12 , ratio: 6 : 40x adenosis\n",
      "n: 87 , ratio: 42 : 40x ductal_carcinoma\n",
      "n: 26 , ratio: 13 : 40x fibroadenoma\n",
      "n: 17 , ratio: 8 : 40x lobular_carcinoma\n",
      "n: 21 , ratio: 10 : 40x mucinous_carcinoma\n",
      "n: 15 , ratio: 7 : 40x papillary_carcinoma\n",
      "n: 12 , ratio: 6 : 40x phyllodes_tumor\n",
      "n: 16 , ratio: 8 : 40x tubular_adenoma\n",
      "206 : Total images with magnitude 40x\n"
     ]
    }
   ],
   "source": [
    "for imgset, imgset_title in zip([image40Xtrain, image40Xval, image40Xtest], ['train','val','test']):\n",
    "    print('\\n', imgset_title)\n",
    "    for i in range(8):\n",
    "        lb = list(imgset.class_indices)[i]\n",
    "        sumclass = sum(imgset.labels==i)\n",
    "        print('n:', sumclass, ', ratio:', round(sumclass/imgset.n*100), ': 40x',lb)\n",
    "    print(imgset.n,': Total images with magnitude 40x',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74854d28-e65c-4031-aa78-bcdde8d9bf1c",
   "metadata": {},
   "source": [
    "## 6. Transfer-learnig by using EfficentNetB0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077b0df",
   "metadata": {},
   "source": [
    "> **The typical transfer-learning workflow**\n",
    "\n",
    "> 1. Instantiate a base model and load pre-trained weights into it.\n",
    "> 1. Freeze all layers in the base model by setting trainable = False.\n",
    "> 1. Create a new model on top of the output of one (or several) layers from the base model.\n",
    "> 1. Train your new model on your new dataset.\n",
    "\n",
    "> see [The typical transferlearning workflow](https://keras.io/guides/transfer_learning/#the-typical-transferlearning-workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94a748-c83b-42ef-a2c4-a1bc886d88f9",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d76cf82",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035dfeb1",
   "metadata": {},
   "source": [
    "The following workflow is adapted from [An end-to-end example: fine-tuning an image classification model on a cats vs. dogs dataset](https://keras.io/guides/transfer_learning/#an-endtoend-example-finetuning-an-image-classification-model-on-a-cats-vs-dogs-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf077b",
   "metadata": {},
   "source": [
    "#### 1. Instantiate a base model and load pre-trained weights into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04acad35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 11:51:04.105075: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Random data augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1),]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce11c295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base model is EfficientNetB0\n",
    "base_model = keras.applications.EfficientNetB0(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(460, 700, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7568bebd-5b86-41b9-aa8a-2cea15c0c6ee",
   "metadata": {},
   "source": [
    "#### 2. Freeze all layers in the base model by setting trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89b57f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze the base_model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90888fea-c8d9-4835-8dc3-9491bddc35c8",
   "metadata": {},
   "source": [
    "#### 3. Create a new model on top of the output of one (or several) layers from the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7049185b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(460, 700, 3))\n",
    "x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "#x = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d346ebd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-trained EfficientNetB0 weights requires that input be in a range of (0, 255)\n",
    "\n",
    "# Therefore skip the following lines:\n",
    "# Pre-trained Xception weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "#scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "#x = scale_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de71cd79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 460, 700, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 460, 700, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 15, 22, 1280)      4049571   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 10248     \n",
      "=================================================================\n",
      "Total params: 4,059,819\n",
      "Trainable params: 10,248\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(8)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799db958",
   "metadata": {},
   "source": [
    "#### 4. Train your new model on your new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4285e5a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    #loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    #metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    #optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c863bbc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# End training when accuracy stops improving (optional)\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36b3a184",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number: 0\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.5000\n",
      "batch number: 1\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "batch number: 2\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "batch number: 3\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "batch number: 4\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "batch number: 5\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "batch number: 6\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "batch number: 7\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "batch number: 8\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.5000\n",
      "batch number: 9\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "batch number: 10\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.5000 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "batch number: 11\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.5000 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "batch number: 12\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "batch number: 13\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.5596 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "batch number: 14\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "batch number: 15\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "batch number: 16\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 1.5596 - val_acc: 0.2500\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 3.9471 - val_acc: 0.2500\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 4.2175 - val_acc: 0.2500\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 4.3348 - val_acc: 0.2500\n",
      "batch number: 17\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.5000 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.5000 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 4.4759 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 4.6494 - val_acc: 0.0000e+00\n",
      "batch number: 18\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "batch number: 19\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Train model with a subsample\n",
    "image40Xtrain.reset()\n",
    "for i in range(20):\n",
    "    print('batch number:',i)\n",
    "    train_imgs, train_lbs = image40Xtrain.next()\n",
    "    val_imgs, val_lbs = image40Xval.next()\n",
    "    epochs = 5 #20\n",
    "    model.fit(\n",
    "        x=train_imgs, \n",
    "        y=train_lbs, \n",
    "        epochs=epochs, \n",
    "        validation_data=(val_imgs, val_lbs),\n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "883ca76f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "372/399 [==========================>...] - ETA: 34s - loss: 2.9885 - acc: 0.2106"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train model with whole sample\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# todo: preprocess_input ?\u001b[39;00m\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m#20\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage40Xtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage40Xval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/my-exts-ml/lib/python3.9/site-packages/keras/engine/training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/my-exts-ml/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/my-exts-ml/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/my-exts-ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3037\u001b[0m   (graph_function,\n\u001b[1;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/my-exts-ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m     args,\n\u001b[1;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1968\u001b[0m     executing_eagerly)\n\u001b[1;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/my-exts-ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/my-exts-ml/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model with whole sample\n",
    "epochs = 2 #20\n",
    "history = model.fit(\n",
    "    x=image40Xtrain, \n",
    "    validation_data=image40Xval, \n",
    "    epochs=epochs, \n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e0593b",
   "metadata": {},
   "source": [
    "#### 5. (Additonal step) Do a round of fine-tuning of the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9cdb2f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 460, 700, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 460, 700, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 15, 22, 1280)      4049571   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 10248     \n",
      "=================================================================\n",
      "Total params: 4,059,819\n",
      "Trainable params: 4,017,796\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "base_model.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b3ae35f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    #loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    #metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82c865f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 19s 19s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 6s 6s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18a282790>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 2 #10\n",
    "model.fit(\n",
    "    x=train_imgs, \n",
    "    y=train_lbs, \n",
    "    epochs=epochs, \n",
    "    validation_data=(val_imgs, val_lbs),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a4ebf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model with whole sample\n",
    "epochs = 2 #20\n",
    "history = model.fit(\n",
    "    x=image40Xtrain, \n",
    "    validation_data=image40Xval, \n",
    "    epochs=epochs, \n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263df76",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58624d4f-d710-48f8-b03b-2c5d3ec90d4b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1718d-e2e9-46e5-bb7b-5da2d82c00f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
