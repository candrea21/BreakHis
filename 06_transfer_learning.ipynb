{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b935eaef",
   "metadata": {},
   "source": [
    "# Transfer Learning (EfficientNetB0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392c525-ba63-4849-9c84-ac916e4e4a2b",
   "metadata": {},
   "source": [
    "Instead of extracting high-level features, one can use pretrained models directly for classfication by adding some output layers. It is also possible to fine-tune such a model, though it is very ressource consuming.\n",
    "\n",
    "I use here the original images, as data augmentation is done by two added input layers for random horizontal flipping and random rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de4ae9-a397-46fd-9fed-96ad0dade98a",
   "metadata": {},
   "source": [
    "## 1. Models used for high-level feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85196d20-1ba9-48e7-952a-803a4dcb499a",
   "metadata": {},
   "source": [
    " **Model**         | **Size (MB)** | **Top-1 Accuracy** | **Top-5 Accuracy** | **Parameters** | **Depth** | **Time (ms) per inference step (CPU)** | **Time (ms) per inference step (GPU)** \n",
    "------------------:|--------------:|-------------------:|-------------------:|---------------:|----------:|---------------------------------------:|---------------------------------------:\n",
    " InceptionV3       | 92            | 0.779              | 0.937              | 23,851,784     | 159       | 42.25                                  | 6.86                                   \n",
    " *EfficientNetB0*    | 29            | -                  | -                  | 5,330,571      | -         | 46                                     | 4.91                                   \n",
    " ResNet50          | 98            | 0.749              | 0.921              | 25,636,712     | -         | 58.2                                   | 4.55                                   \n",
    " VGG16             | 528           | 0.713              | 0.901              | 138,357,544    | 23        | 69.5                                   | 4.16                                   \n",
    " DenseNet121       | 33            | 0.75               | 0.923              | 8,062,504      | 121       | 77.14                                  | 5.38                                   \n",
    " Xception          | 88            | 0.79               | 0.945              | 22,910,480     | 126       | 109.42                                 | 8.06                                   \n",
    " InceptionResNetV2 | 215           | 0.803              | 0.953              | 55,873,736     | 572       | 130.19                                 | 10.02                                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b81d7-6cef-4511-9297-b8b44e69366e",
   "metadata": {},
   "source": [
    "> Data source: https://keras.io/api/applications/#available-models  \n",
    "> Table converter: https://tableconvert.com/excel-to-markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c61ed7-24ad-43de-8fd7-b2966565900c",
   "metadata": {},
   "source": [
    "For transfer learning I will use EfficientNetB0, as it is the most lightweight model (smallest size, least parameters) from the ones listed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac2ec4-5d94-4621-b009-32c41eac6e17",
   "metadata": {},
   "source": [
    "## 2. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f9d2a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd44263-5da7-4531-9801-1c50270f87c9",
   "metadata": {},
   "source": [
    "## 3. Structure of `data/split` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2fcf8-6abb-47c6-bce6-d5a7940c76ca",
   "metadata": {},
   "source": [
    "```\n",
    "data/split\n",
    "└── 40X\n",
    "    ├── test\n",
    "    │   ├── adenosis\n",
    "    │   ├── ductal_carcinoma\n",
    "    │   ├── fibroadenoma\n",
    "    │   ├── lobular_carcinoma\n",
    "    │   ├── mucinous_carcinoma\n",
    "    │   ├── papillary_carcinoma\n",
    "    │   ├── phyllodes_tumor\n",
    "    │   └── tubular_adenoma\n",
    "    ├── train\n",
    "    │   ├── adenosis\n",
    "    │   ├── ductal_carcinoma\n",
    "    │   ├── fibroadenoma\n",
    "    │   ├── lobular_carcinoma\n",
    "    │   ├── mucinous_carcinoma\n",
    "    │   ├── papillary_carcinoma\n",
    "    │   ├── phyllodes_tumor\n",
    "    │   └── tubular_adenoma\n",
    "    └── val\n",
    "        ├── adenosis\n",
    "        ├── ductal_carcinoma\n",
    "        ├── fibroadenoma\n",
    "        ├── lobular_carcinoma\n",
    "        ├── mucinous_carcinoma\n",
    "        ├── papillary_carcinoma\n",
    "        ├── phyllodes_tumor\n",
    "        └── tubular_adenoma\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a9a5d",
   "metadata": {},
   "source": [
    "## 4. Define image data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60745953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data generator for train\n",
    "image_generator_train = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d115c5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data generator validation and test\n",
    "image_generator_valtest = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec488d98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "image40Xtrain = image_generator_train.flow_from_directory(\n",
    "    os.path.join('data','split','40X','train'),\n",
    "    batch_size=4, # very small batch size to preserve RAM\n",
    "    target_size=(460, 700),\n",
    "    class_mode = 'sparse',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c50481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 195 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "image40Xval = image_generator_valtest.flow_from_directory(\n",
    "    os.path.join('data','split','40X','val'),\n",
    "    batch_size=4, \n",
    "    target_size=(460, 700),\n",
    "    class_mode = 'sparse',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5114e53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "image40Xtest = image_generator_valtest.flow_from_directory(\n",
    "    os.path.join('data','split','40X','test'),\n",
    "    batch_size=4, \n",
    "    target_size=(460, 700),\n",
    "    class_mode = 'sparse',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43b400",
   "metadata": {},
   "source": [
    "#### Print shape of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ff6b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: (4, 460, 700, 3)\n",
      "Labels: (4,)\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = image40Xtrain.next()\n",
    "print('Images:', imgs.shape)\n",
    "print('Labels:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05fa0e-5e9d-436e-b05d-729be9e3e3a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Print range of pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75018546-18fb-42ac-b8d2-ea328d580ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest pixel value: 38.0 \n",
      "highest pixel value: 255.0\n"
     ]
    }
   ],
   "source": [
    "print('lowest pixel value:',np.min(imgs), '\\nhighest pixel value:', np.max(imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b99827-dec3-4909-ba16-2d390a3c8953",
   "metadata": {},
   "source": [
    "Pixel values range are in the range between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82659bcf",
   "metadata": {},
   "source": [
    "## 5. Number of images per class for magnitude 40x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14197e-6452-484e-a0a4-30b20d61b57f",
   "metadata": {},
   "source": [
    "Check number of images for each class in each set (train, validation, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b06b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nperclass = []\n",
    "for imgset, imgset_title in zip([image40Xtrain, image40Xval, image40Xtest], ['train','val','test']):\n",
    "    #print('\\n', imgset_title)\n",
    "    for i in range(8):\n",
    "        lb = list(imgset.class_indices)[i]\n",
    "        sumclass = sum(imgset.labels==i)\n",
    "        #print(lb, '\\n   n:', sumclass, '\\n   percentage:', '{:.2%}'.format(sumclass/imgset.n))\n",
    "        nperclass.append({\n",
    "            'set': imgset_title,\n",
    "            'class': lb,\n",
    "            'sumclass': sumclass,\n",
    "            'proportion': '{:.2%}'.format(sumclass/imgset.n)\n",
    "        })\n",
    "    #print(imgset.n,': Total images with magnitude 40x',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed556a61-4be4-460c-980d-3665e608a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncl = pd.DataFrame(nperclass)\n",
    "tr_df = ncl.iloc[:8,]\n",
    "val_df = ncl.iloc[8:16,]\n",
    "te_df = ncl.iloc[16:24,]\n",
    "tr_df.set_index(['class'], inplace=True)\n",
    "val_df.set_index(['class'], inplace=True)\n",
    "te_df.set_index(['class'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ba89caa-0fac-4d48-938e-3fa397ace159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>sumclass</th>\n",
       "      <th>proportion</th>\n",
       "      <th>set</th>\n",
       "      <th>sumclass</th>\n",
       "      <th>proportion</th>\n",
       "      <th>set</th>\n",
       "      <th>sumclass</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adenosis</th>\n",
       "      <td>train</td>\n",
       "      <td>91</td>\n",
       "      <td>5.71%</td>\n",
       "      <td>val</td>\n",
       "      <td>11</td>\n",
       "      <td>5.64%</td>\n",
       "      <td>test</td>\n",
       "      <td>12</td>\n",
       "      <td>5.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ductal_carcinoma</th>\n",
       "      <td>train</td>\n",
       "      <td>691</td>\n",
       "      <td>43.35%</td>\n",
       "      <td>val</td>\n",
       "      <td>86</td>\n",
       "      <td>44.10%</td>\n",
       "      <td>test</td>\n",
       "      <td>87</td>\n",
       "      <td>42.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fibroadenoma</th>\n",
       "      <td>train</td>\n",
       "      <td>202</td>\n",
       "      <td>12.67%</td>\n",
       "      <td>val</td>\n",
       "      <td>25</td>\n",
       "      <td>12.82%</td>\n",
       "      <td>test</td>\n",
       "      <td>26</td>\n",
       "      <td>12.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobular_carcinoma</th>\n",
       "      <td>train</td>\n",
       "      <td>124</td>\n",
       "      <td>7.78%</td>\n",
       "      <td>val</td>\n",
       "      <td>15</td>\n",
       "      <td>7.69%</td>\n",
       "      <td>test</td>\n",
       "      <td>17</td>\n",
       "      <td>8.25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mucinous_carcinoma</th>\n",
       "      <td>train</td>\n",
       "      <td>164</td>\n",
       "      <td>10.29%</td>\n",
       "      <td>val</td>\n",
       "      <td>20</td>\n",
       "      <td>10.26%</td>\n",
       "      <td>test</td>\n",
       "      <td>21</td>\n",
       "      <td>10.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papillary_carcinoma</th>\n",
       "      <td>train</td>\n",
       "      <td>116</td>\n",
       "      <td>7.28%</td>\n",
       "      <td>val</td>\n",
       "      <td>14</td>\n",
       "      <td>7.18%</td>\n",
       "      <td>test</td>\n",
       "      <td>15</td>\n",
       "      <td>7.28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phyllodes_tumor</th>\n",
       "      <td>train</td>\n",
       "      <td>87</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>val</td>\n",
       "      <td>10</td>\n",
       "      <td>5.13%</td>\n",
       "      <td>test</td>\n",
       "      <td>12</td>\n",
       "      <td>5.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tubular_adenoma</th>\n",
       "      <td>train</td>\n",
       "      <td>119</td>\n",
       "      <td>7.47%</td>\n",
       "      <td>val</td>\n",
       "      <td>14</td>\n",
       "      <td>7.18%</td>\n",
       "      <td>test</td>\n",
       "      <td>16</td>\n",
       "      <td>7.77%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       set  sumclass proportion  set  sumclass proportion  \\\n",
       "class                                                                       \n",
       "adenosis             train        91      5.71%  val        11      5.64%   \n",
       "ductal_carcinoma     train       691     43.35%  val        86     44.10%   \n",
       "fibroadenoma         train       202     12.67%  val        25     12.82%   \n",
       "lobular_carcinoma    train       124      7.78%  val        15      7.69%   \n",
       "mucinous_carcinoma   train       164     10.29%  val        20     10.26%   \n",
       "papillary_carcinoma  train       116      7.28%  val        14      7.18%   \n",
       "phyllodes_tumor      train        87      5.46%  val        10      5.13%   \n",
       "tubular_adenoma      train       119      7.47%  val        14      7.18%   \n",
       "\n",
       "                      set  sumclass proportion  \n",
       "class                                           \n",
       "adenosis             test        12      5.83%  \n",
       "ductal_carcinoma     test        87     42.23%  \n",
       "fibroadenoma         test        26     12.62%  \n",
       "lobular_carcinoma    test        17      8.25%  \n",
       "mucinous_carcinoma   test        21     10.19%  \n",
       "papillary_carcinoma  test        15      7.28%  \n",
       "phyllodes_tumor      test        12      5.83%  \n",
       "tubular_adenoma      test        16      7.77%  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([tr_df, val_df, te_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271d8d0-3199-4b0b-85e7-1b877fa10c35",
   "metadata": {},
   "source": [
    "As we see, proportion of each class was preserved by splitting in training, validation, and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74854d28-e65c-4031-aa78-bcdde8d9bf1c",
   "metadata": {},
   "source": [
    "## 6. Transfer-learnig by using EfficentNetB0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077b0df",
   "metadata": {},
   "source": [
    "> **The typical transfer-learning workflow**\n",
    "\n",
    "> 1. Instantiate a base model and load pre-trained weights into it.\n",
    "> 1. Freeze all layers in the base model by setting trainable = False.\n",
    "> 1. Create a new model on top of the output of one (or several) layers from the base model.\n",
    "> 1. Train your new model on your new dataset.\n",
    "\n",
    "> see [The typical transferlearning workflow](https://keras.io/guides/transfer_learning/#the-typical-transferlearning-workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94a748-c83b-42ef-a2c4-a1bc886d88f9",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d76cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035dfeb1",
   "metadata": {},
   "source": [
    "The following workflow is adapted from [An end-to-end example: fine-tuning an image classification model on a cats vs. dogs dataset](https://keras.io/guides/transfer_learning/#an-endtoend-example-finetuning-an-image-classification-model-on-a-cats-vs-dogs-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf077b",
   "metadata": {},
   "source": [
    "#### 1. Instantiate a base model and load pre-trained weights into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04acad35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 18:11:37.939894: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Random data augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1),]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce11c295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base model is EfficientNetB0\n",
    "base_model = keras.applications.EfficientNetB0(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(460, 700, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7568bebd-5b86-41b9-aa8a-2cea15c0c6ee",
   "metadata": {},
   "source": [
    "#### 2. Freeze all layers in the base model by setting `trainable = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89b57f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze the base_model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90888fea-c8d9-4835-8dc3-9491bddc35c8",
   "metadata": {},
   "source": [
    "#### 3. Create a new model on top of the output of one (or several) layers from the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7049185b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(460, 700, 3))\n",
    "x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "#x = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d346ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-trained EfficientNetB0 weights requires that input be in a range of (0, 255)\n",
    "# Therefore skip the following lines:\n",
    "\n",
    "# Pre-trained Xception weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "#scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "#x = scale_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de71cd79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 460, 700, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 460, 700, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 15, 22, 1280)      4049571   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 10248     \n",
      "=================================================================\n",
      "Total params: 4,059,819\n",
      "Trainable params: 10,248\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "\n",
    "# inference mode: _using_ the model (for prediction), in contrast to _train_ a model\n",
    "# batchnorm layer: \n",
    "#   Batch normalization applies a transformation that maintains the mean output close to 0 \n",
    "#   and the output standard deviation close to 1.\n",
    "#   Importantly, batch normalization works differently during training and during inference.\n",
    "#   During training (training=True), the layer normalizes its output using the mean and standard deviation \n",
    "#      of the current batch of inputs. \n",
    "#   During inference (training=False), the layer normalizes its output using a moving average of the mean and standard deviation \n",
    "#      of the batches it has seen during training. \n",
    "#   See https://keras.io/api/layers/normalization_layers/batch_normalization/\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(8)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799db958",
   "metadata": {},
   "source": [
    "#### 4. Train your new model on your new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4285e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    #optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c863bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# End training when accuracy stops improving (optional)\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b3a184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 18:11:41.230347: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 10s 10s/step - loss: 8.6077 - acc: 0.5000 - val_loss: 15.5441 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 12.1552 - acc: 0.0000e+00 - val_loss: 11.9343 - val_acc: 0.0000e+00\n",
      "batch number: 1\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.7501 - acc: 0.0000e+00 - val_loss: 14.1148 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.1582 - acc: 0.0000e+00 - val_loss: 11.1130 - val_acc: 0.0000e+00\n",
      "batch number: 2\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.5372 - acc: 0.0000e+00 - val_loss: 5.1655 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.7578 - acc: 0.0000e+00 - val_loss: 4.8305 - val_acc: 0.0000e+00\n",
      "batch number: 3\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.0870 - acc: 0.0000e+00 - val_loss: 5.2567 - val_acc: 0.2500\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.5596 - acc: 0.2500 - val_loss: 5.1444 - val_acc: 0.2500\n",
      "batch number: 4\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.3223 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.8307 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "batch number: 5\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 5.2970 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 5.2711 - val_acc: 0.0000e+00\n",
      "batch number: 6\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.2300 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "batch number: 7\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.0000e+00 - val_loss: 2.0794 - val_acc: 0.0000e+00\n",
      "batch number: 8\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.0949 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.3299 - acc: 0.2500 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "batch number: 9\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.1704 - acc: 0.5000 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0794 - acc: 0.5000 - val_loss: 2.0794 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "# Train model with a subsample\n",
    "image40Xtrain.reset()\n",
    "for i in range(10):\n",
    "    print('batch number:',i)\n",
    "    train_imgs, train_lbs = image40Xtrain.next()\n",
    "    val_imgs, val_lbs = image40Xval.next()\n",
    "    epochs = 2 #20\n",
    "    model.fit(\n",
    "        x=train_imgs, \n",
    "        y=train_lbs, \n",
    "        epochs=epochs, \n",
    "        validation_data=(val_imgs, val_lbs),\n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "883ca76f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model with whole sample\n",
    "if False:\n",
    "    epochs = 20\n",
    "    history = model.fit(\n",
    "        x=image40Xtrain, \n",
    "        validation_data=image40Xval, \n",
    "        epochs=epochs, \n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e0593b",
   "metadata": {},
   "source": [
    "#### 5. (Additonal step) Do a round of fine-tuning of the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9cdb2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 460, 700, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 460, 700, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 15, 22, 1280)      4049571   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 10248     \n",
      "=================================================================\n",
      "Total params: 4,059,819\n",
      "Trainable params: 4,017,796\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "base_model.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ca0b4-98a0-472e-aa0b-3bf0e38d0497",
   "metadata": {},
   "source": [
    "Note here the amount of trainable params, compared to model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b3ae35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82c865f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 17s 17s/step - loss: 2.0794 - acc: 0.5000 - val_loss: 2.0794 - val_acc: 0.2500\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 6s 6s/step - loss: 2.0794 - acc: 0.5000 - val_loss: 2.0794 - val_acc: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c8b30a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 2 #10\n",
    "model.fit(\n",
    "    x=train_imgs, \n",
    "    y=train_lbs, \n",
    "    epochs=epochs, \n",
    "    validation_data=(val_imgs, val_lbs),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af3a4ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model with whole sample\n",
    "if False:\n",
    "    epochs = 20\n",
    "    history = model.fit(\n",
    "        x=image40Xtrain, \n",
    "        validation_data=image40Xval, \n",
    "        epochs=epochs, \n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
