{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b935eaef",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de4ae9-a397-46fd-9fed-96ad0dade98a",
   "metadata": {},
   "source": [
    "#### Models used for high-level feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85196d20-1ba9-48e7-952a-803a4dcb499a",
   "metadata": {},
   "source": [
    " **Model**         | **Size (MB)** | **Top-1 Accuracy** | **Top-5 Accuracy** | **Parameters** | **Depth** | **Time (ms) per inference step (CPU)** | **Time (ms) per inference step (GPU)** \n",
    "------------------:|--------------:|-------------------:|-------------------:|---------------:|----------:|---------------------------------------:|---------------------------------------:\n",
    " InceptionV3       | 92            | 0.779              | 0.937              | 23,851,784     | 159       | 42.25                                  | 6.86                                   \n",
    " *EfficientNetB0*    | 29            | -                  | -                  | 5,330,571      | -         | 46                                     | 4.91                                   \n",
    " ResNet50          | 98            | 0.749              | 0.921              | 25,636,712     | -         | 58.2                                   | 4.55                                   \n",
    " VGG16             | 528           | 0.713              | 0.901              | 138,357,544    | 23        | 69.5                                   | 4.16                                   \n",
    " DenseNet121       | 33            | 0.75               | 0.923              | 8,062,504      | 121       | 77.14                                  | 5.38                                   \n",
    " Xception          | 88            | 0.79               | 0.945              | 22,910,480     | 126       | 109.42                                 | 8.06                                   \n",
    " InceptionResNetV2 | 215           | 0.803              | 0.953              | 55,873,736     | 572       | 130.19                                 | 10.02                                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b81d7-6cef-4511-9297-b8b44e69366e",
   "metadata": {},
   "source": [
    "> Data source: https://keras.io/api/applications/#available-models  \n",
    "> Table converter: https://tableconvert.com/excel-to-markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041af6a5-da3f-4096-ae97-c03ffd0e7e1b",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac2ec4-5d94-4621-b009-32c41eac6e17",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5f9d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd44263-5da7-4531-9801-1c50270f87c9",
   "metadata": {},
   "source": [
    "#### Structure of `data/split` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2fcf8-6abb-47c6-bce6-d5a7940c76ca",
   "metadata": {},
   "source": [
    "```\n",
    "data/split\n",
    "└── 40X\n",
    "    ├── test\n",
    "    │   ├── adenosis\n",
    "    │   ├── ductal_carcinoma\n",
    "    │   ├── fibroadenoma\n",
    "    │   ├── lobular_carcinoma\n",
    "    │   ├── mucinous_carcinoma\n",
    "    │   ├── papillary_carcinoma\n",
    "    │   ├── phyllodes_tumor\n",
    "    │   └── tubular_adenoma\n",
    "    ├── train\n",
    "    │   ├── adenosis\n",
    "    │   ├── ductal_carcinoma\n",
    "    │   ├── fibroadenoma\n",
    "    │   ├── lobular_carcinoma\n",
    "    │   ├── mucinous_carcinoma\n",
    "    │   ├── papillary_carcinoma\n",
    "    │   ├── phyllodes_tumor\n",
    "    │   └── tubular_adenoma\n",
    "    └── val\n",
    "        ├── adenosis\n",
    "        ├── ductal_carcinoma\n",
    "        ├── fibroadenoma\n",
    "        ├── lobular_carcinoma\n",
    "        ├── mucinous_carcinoma\n",
    "        ├── papillary_carcinoma\n",
    "        ├── phyllodes_tumor\n",
    "        └── tubular_adenoma\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a9a5d",
   "metadata": {},
   "source": [
    "#### Define image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60745953",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator_train = ImageDataGenerator(\n",
    "    #rescale=1/127.5,\n",
    "    #rescale=127.5,\n",
    "    #width_shift_range= 10.0,\n",
    "    #height_shift_range= 10.0,\n",
    "    #rotation_range = 20,\n",
    "    #horizontal_flip = True,\n",
    "    #vertical_flip = False,\n",
    "    #zoom_range = 0.1,\n",
    "    #channel_shift_range = 0.2,\n",
    "    #brightness_range = (0,1),\n",
    "    #shear_range = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d115c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator_valtest = ImageDataGenerator(\n",
    "    #rescale=1/127.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ec488d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "image40Xtrain = image_generator_train.flow_from_directory(\n",
    "    os.path.join('data','split','40X','train'),\n",
    "    batch_size=16, \n",
    "    target_size=(460, 700),\n",
    "    class_mode = 'sparse',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "78c50481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 195 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "image40Xval = image_generator_valtest.flow_from_directory(\n",
    "    os.path.join('data','split','40X','val'),\n",
    "    batch_size=16, \n",
    "    target_size=(460, 700),\n",
    "    class_mode = 'sparse',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5114e53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "image40Xtest = image_generator_valtest.flow_from_directory(\n",
    "    os.path.join('data','split','40X','test'),\n",
    "    batch_size=16, \n",
    "    target_size=(460, 700),\n",
    "    class_mode = 'sparse',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b92755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a43b400",
   "metadata": {},
   "source": [
    "#### Print shape of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ff6b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: (16, 460, 700, 3)\n",
      "Labels: (16,)\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = image40Xtrain.next()\n",
    "print('Images:', imgs.shape)\n",
    "print('Labels:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05fa0e-5e9d-436e-b05d-729be9e3e3a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Print range of pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "75018546-18fb-42ac-b8d2-ea328d580ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest pixel value: 23.0 \n",
      "highest pixel value: 255.0\n"
     ]
    }
   ],
   "source": [
    "print('lowest pixel value:',np.min(imgs), '\\nhighest pixel value:', np.max(imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82659bcf",
   "metadata": {},
   "source": [
    "#### Number of images per class for magnitude 40x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4b06b53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " train\n",
      "n: 91 , ratio: 6 : 40x adenosis\n",
      "n: 691 , ratio: 43 : 40x ductal_carcinoma\n",
      "n: 202 , ratio: 13 : 40x fibroadenoma\n",
      "n: 124 , ratio: 8 : 40x lobular_carcinoma\n",
      "n: 164 , ratio: 10 : 40x mucinous_carcinoma\n",
      "n: 116 , ratio: 7 : 40x papillary_carcinoma\n",
      "n: 87 , ratio: 5 : 40x phyllodes_tumor\n",
      "n: 119 , ratio: 7 : 40x tubular_adenoma\n",
      "1594 : Total images with magnitude 40x\n",
      "\n",
      " val\n",
      "n: 11 , ratio: 6 : 40x adenosis\n",
      "n: 86 , ratio: 44 : 40x ductal_carcinoma\n",
      "n: 25 , ratio: 13 : 40x fibroadenoma\n",
      "n: 15 , ratio: 8 : 40x lobular_carcinoma\n",
      "n: 20 , ratio: 10 : 40x mucinous_carcinoma\n",
      "n: 14 , ratio: 7 : 40x papillary_carcinoma\n",
      "n: 10 , ratio: 5 : 40x phyllodes_tumor\n",
      "n: 14 , ratio: 7 : 40x tubular_adenoma\n",
      "195 : Total images with magnitude 40x\n",
      "\n",
      " test\n",
      "n: 12 , ratio: 6 : 40x adenosis\n",
      "n: 87 , ratio: 42 : 40x ductal_carcinoma\n",
      "n: 26 , ratio: 13 : 40x fibroadenoma\n",
      "n: 17 , ratio: 8 : 40x lobular_carcinoma\n",
      "n: 21 , ratio: 10 : 40x mucinous_carcinoma\n",
      "n: 15 , ratio: 7 : 40x papillary_carcinoma\n",
      "n: 12 , ratio: 6 : 40x phyllodes_tumor\n",
      "n: 16 , ratio: 8 : 40x tubular_adenoma\n",
      "206 : Total images with magnitude 40x\n"
     ]
    }
   ],
   "source": [
    "for imgset, imgset_title in zip([image40Xtrain, image40Xval, image40Xtest], ['train','val','test']):\n",
    "    print('\\n', imgset_title)\n",
    "    for i in range(8):\n",
    "        lb = list(imgset.class_indices)[i]\n",
    "        sumclass = sum(imgset.labels==i)\n",
    "        print('n:', sumclass, ', ratio:', round(sumclass/imgset.n*100), ': 40x',lb)\n",
    "    print(imgset.n,': Total images with magnitude 40x',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077b0df",
   "metadata": {},
   "source": [
    "> **The typical transfer-learning workflow**\n",
    "\n",
    "> 1. Instantiate a base model and load pre-trained weights into it.\n",
    "> 1. Freeze all layers in the base model by setting trainable = False.\n",
    "> 1. Create a new model on top of the output of one (or several) layers from the base model.\n",
    "> 1. Train your new model on your new dataset.\n",
    "\n",
    "> see [The typical transferlearning workflow](https://keras.io/guides/transfer_learning/#the-typical-transferlearning-workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6d76cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d62c4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "035dfeb1",
   "metadata": {},
   "source": [
    "https://keras.io/guides/transfer_learning/#an-endtoend-example-finetuning-an-image-classification-model-on-a-cats-vs-dogs-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf077b",
   "metadata": {},
   "source": [
    "#### Using random data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "04acad35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1),]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ce11c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.EfficientNetB0(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(460, 700, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "89b57f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base_model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7049185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(460, 700, 3))\n",
    "x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "#x = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1d346ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained Xception weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "#scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "#x = scale_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "de71cd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 460, 700, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 460, 700, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 15, 22, 1280)      4049571   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 10248     \n",
      "=================================================================\n",
      "Total params: 4,059,819\n",
      "Trainable params: 10,248\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(8)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799db958",
   "metadata": {},
   "source": [
    "#### Train the top layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a4285e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    #loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    #metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    #optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1c863bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End training when accuracy stops improving (optional)\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "36b3a184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 17s 17s/step - loss: 11.8864 - acc: 0.1250 - val_loss: 12.3509 - val_acc: 0.0625\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 9s 9s/step - loss: 10.8090 - acc: 0.1250 - val_loss: 12.2616 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ba0a7f0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model with subsample\n",
    "image40Xtrain.reset()\n",
    "train_imgs, train_lbs = image40Xtrain.next()\n",
    "val_imgs, val_lbs = image40Xval.next()\n",
    "epochs = 2 #20\n",
    "model.fit(\n",
    "    x=train_imgs, \n",
    "    y=train_lbs, \n",
    "    epochs=epochs, \n",
    "    validation_data=(val_imgs, val_lbs),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e6bf12f0-3121-4696-924d-7d7938dbde10",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: top_conv.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop_conv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/my-exts-ml/lib/python3.9/site-packages/keras/engine/training.py:2568\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   2566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name:\n\u001b[1;32m   2567\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[0;32m-> 2568\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo such layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProvide either a layer name or layer index.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: top_conv."
     ]
    }
   ],
   "source": [
    "model.get_layer('top_conv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a1dff7-16e9-4e47-8d4a-4782e3584a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "883ca76f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-20-4d2cbefef5cf>\", line 7, in <module>\n",
      "    callbacks=[early_stopping]\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 2177, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 176, in fit_generator\n",
      "    x, y, sample_weight=sample_weight, class_weight=class_weight)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1940, in train_on_batch\n",
      "    outputs = self.train_function(ins)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 2986, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-4d2cbefef5cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 176\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/exts-ml/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Train model with whole sample\n",
    "# todo: preprocess_input ?\n",
    "epochs = 2 #20\n",
    "history = model.fit_generator(\n",
    "    generator=image40Xtrain, \n",
    "    validation_data=image40Xval, \n",
    "    epochs=epochs, \n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e0593b",
   "metadata": {},
   "source": [
    "#### Do a round of fine-tuning of the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9cdb2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 460, 700, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 460, 700, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 15, 22, 1280)      4049571   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 10248     \n",
      "=================================================================\n",
      "Total params: 4,059,819\n",
      "Trainable params: 4,017,796\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "base_model.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b3ae35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    #loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    #metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c865f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "#train_imgs, train_labels = image40Xtrain.next()\n",
    "#val_imgs, val_labels = image40Xval.next()\n",
    "#X_tr = preprocess_input(train_imgs)\n",
    "#X_val = preprocess_input(val_imgs)\n",
    "\n",
    "epochs = 2 #10\n",
    "model.fit(\n",
    "    x=train_imgs, \n",
    "    y=train_lbs, \n",
    "    epochs=epochs, \n",
    "    validation_data=(val_imgs, val_lbs),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with whole sample\n",
    "# todo: preprocess_input ?\n",
    "epochs = 2 #20\n",
    "history = model.fit_generator(\n",
    "    generator=image40Xtrain, \n",
    "    validation_data=image40Xval, \n",
    "    epochs=epochs, \n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ed8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eaf236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf8286e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc71f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42e4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99625bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9b8138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14cc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e447a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c747a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ff7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263df76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "404aa4cd",
   "metadata": {},
   "source": [
    "#### First, instantiate a base model with pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daec4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "# I use average pooling here, may change during process\n",
    "base_model = Xception(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(460,700,3), \n",
    "    #pooling='avg' #'max'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e49852",
   "metadata": {},
   "source": [
    "#### Then, freeze the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0c0e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068c7bc",
   "metadata": {},
   "source": [
    "#### Create a new model on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "275ed1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(460, 700, 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning.\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954a79df",
   "metadata": {},
   "source": [
    "#### Train the model on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd2cdc9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.keras.losses' has no attribute 'BinaryCrossentropy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fba43644abf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compile(optimizer=keras.optimizers.Adam(),\n\u001b[0;32m----> 2\u001b[0;31m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m               metrics=[keras.metrics.BinaryAccuracy()])\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.keras.losses' has no attribute 'BinaryCrossentropy'"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])\n",
    "model.fit(new_dataset, epochs=20, callbacks=..., validation_data=...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ffeb7d",
   "metadata": {},
   "source": [
    "#### This is how to implement fine-tuning of the whole base model:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
